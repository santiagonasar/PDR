import sys
import os
import csv


def read_ncbi_disease_dataset(directory):
    datasets = ["NCBI_corpus_development", "NCBI_corpus_testing", "NCBI_corpus_training"]

    ncbi = {}

    if os.path.isdir(directory):
        for dataset in datasets:
            if os.path.isfile(directory + "/" + dataset + ".txt"):
                with open(directory + "/" + dataset + ".txt") as f:
                    # read dataset
                    ncbi[dataset] = read_ncbi_disease_subset(f)

            else:
                raise Exception("No file: " + dataset + ".txt")
    else:
        raise Exception("No directory: " + directory)

    return ncbi


def read_ncbi_disease_subset(file):
    ncbi_subset = []
    ncbi_in = csv.reader(file, delimiter='\t')
    for line in ncbi_in:
        ncbi_subset.append({"PMC": line[0],
                            "Title": line[1],
                            "Abstract": line[2]})
    return ncbi_subset


def split_ncbi_subset_into_files(ncbi_subset, ncbi_destination):
    os.system('rm -rf ' + ncbi_destination + ' || true')
    os.system('mkdir -p ' + ncbi_destination + ' || true')

    for article in ncbi_subset:
        PMC = article["PMC"]
        abstract = article["Abstract"]
        path = ncbi_destination + '/' + PMC + '.txt'

        with open(path, mode='w') as f:
            f.write(abstract)


def split_ncbi_into_separate_files_and_merge_train_dev(ncbi_path, ncbi_destination):
    ncbi = read_ncbi_disease_dataset(ncbi_path)

    ncbi_train = ncbi["NCBI_corpus_training"]
    ncbi_dev = ncbi["NCBI_corpus_development"]
    ncbi_test = ncbi["NCBI_corpus_testing"]
    # merge train and dev
    ncbi_train_dev = ncbi_train + ncbi_dev

    # split
    split_ncbi_subset_into_files(ncbi_train_dev, ncbi_destination + '/ncbi_train')
    split_ncbi_subset_into_files(ncbi_test, ncbi_destination + '/ncbi_test')


def divide_directory(corpus_path, directory_path):
    """Divides files from the corpus directory into different directories

    :param corpus_path: corpus path
    :param directory_path: per directory corpus path
    :return: directories with divided by sentences corpus (each with 500 abstracts and one with the leftovers)
    """

    for (dir_path, dir_names, file_names) in os.walk(corpus_path):

        number_directories = int(len(file_names) / 500) + 1

        for u in range(number_directories):
            os.system('mkdir -p ' + directory_path + 'directory_' + str(u) + ' || true')

    for (dir_path, dir_names, file_names) in os.walk(corpus_path):

        for i in range(number_directories):

            counter = 0
            os.system('rm -rf ' + directory_path + '/directory_' + str(i) + '/* || true')

            for filename in file_names:

                counter += 1

                if counter <= 500:
                    os.system('cp ' + corpus_path + filename + ' ' + directory_path + '/directory_' + str(i) + '/')

                else:
                    file_names = file_names[500:]
                    break

    return number_directories

def copy_ncbi(corpus_path, directory_path):
    """Divides files from the corpus directory into different directories

    :param corpus_path: corpus path
    :param directory_path: new corpus path
    """
    os.system('rm -rf ' + directory_path + '/* || true')

    for (dir_path, dir_names, file_names) in os.walk(corpus_path):
        for filename in file_names:
            os.system('cp ' + corpus_path + filename + ' ' + directory_path + '/')


#### JOIN REPORT IHP FILES IN ONE FINAL REPORT ####

def join_report_files(annotations_path):
    """Joins the seven report files generated by the IHP tool (see docstring from divided_directory) in one final report file

    :param annotations_path: per directory annotations path
    :return: file with joined report files
    """

    final_report = open(annotations_path + 'final_report', 'w', encoding='utf-8')

    for (dir_path, dir_names, file_names) in os.walk(annotations_path):

        for filename in file_names:

            if filename.startswith('directory'):
                directory_file = open(annotations_path + filename, 'r', encoding='utf-8')
                directory_content = directory_file.read().split('>')[-1][2:-1]
                directory_file.close()

                final_report.write(directory_content + '\n')

    final_report.close()

    return



def main():
    os.system('mkdir -p corpora/ncbi_text || true')
    os.system('mkdir -p corpora/ncbi_annotations || true')
    os.system('mkdir -p corpora/ncbi_divided_by_sentences_annotations || true')
    os.system('mkdir -p corpora/ncbi_added_annotations || true')
    os.system('mkdir -p corpora/disease_phenotype_annotations || true')
    os.system('unzip -d corpora/NCBI-disease corpora/NCBI_corpus.zip'
              ' || true')

    # remove xml tags
    os.system('python3 bin/xmlAnn/src/main.py remove-xml corpora/NCBI-disease corpora/NCBI-disease-no-xml')
    os.system('rm -rf corpora/NCBI-disease')
    os.system('mv corpora/NCBI-disease-no-xml corpora/NCBI-disease')

    split_ncbi_into_separate_files_and_merge_train_dev('corpora/NCBI-disease', 'corpora/NCBI-disease-no-xml')
    # delete old ncbi-disease
    os.system("rm -rf corpora/NCBI-disease")
    os.system("mv corpora/NCBI-disease-no-xml corpora/NCBI-disease")

    # copy the contents of train to corpora/ncbi_text

    copy_ncbi('corpora/NCBI-disease/ncbi_train/', 'corpora/ncbi_text/')

    os.system('cp corpora/ncbi_text/* bin/IHP/corpora/hpo/test_corpus/')
    os.chdir('bin/IHP/')
    os.system('python3 src/main.py load_corpus --goldstd hpo_test --log DEBUG')
    os.system(
      'python3 src/main.py test --goldstd hpo_test -o pickle data/results_hpo_train --models models/hpo_train '
      '--log DEBUG')
    os.system(
      'python3 src/evaluate.py evaluate hpo_test --results data/results_hpo_train --models models/hpo_train '
      '--log DEBUG')
    os.system('ls -la')
    os.system('ls -la ../../corpora/ncbi_annotation')
    os.system('ls -la data/')
    os.system(
       'mv data/results_hpo_train_report.txt ../../corpora/ncbi_annotation')
    os.chdir('../..')
    # os.system('rm bin/IHP/corpora/hpo/test_corpus/* || true')

    # not needed, as everything in one directory already
    join_report_files('corpora/ncbi_annotations/')
    os.chdir('bin/MER/')

    # os.system('cd data; ../produce_data_files.sh genes.txt')
    # annotations('../../corpora/pubmed_corpus/', 'get_entities.sh','../../corpora/per_directory_annotations/final_report', 'data/hp_links.tsv', '../../corpora/')
    # os.chdir('../..')
    # update_annotations('corpora/pubmed_corpus/', 'data/', 'corpora/divided_by_sentences_annotations/','corpora/annotations_to_check.tsv', 'bin/MER/data/', 'corpora/added_annotations/')
    # final_annotations('corpora/added_annotations/', 'corpora/pubmed_corpus/', 'corpora/new_corpus/', 'corpora/gene_phenotype_annotations/')
    # os.system('rm corpora/pubmed_corpus/* || true')
    # os.system('mv corpora/new_corpus/* corpora/pubmed_corpus/ || true')
    # relations_annotations('corpora/pubmed_corpus/', 'data/ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt', 'data/ALL_SOURCES_ALL_FREQUENCIES_phenotype_to_genes.txt', 'corpora/gene_phenotype_annotations/', 'corpora/relations.tsv')
    # #verify_relations_annotations('corpora/')  # if curator confirmation for a test corpus
    # os.system('rm -rf corpora/per_directory_text corpora/per_directory_annotations corpora/divided_by_sentences_annotations corpora/added_annotations corpora/new_corpus || true')

    return


if __name__ == "__main__":
    main()